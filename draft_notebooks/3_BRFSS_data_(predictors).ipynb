{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get variable names and descriptions from BRFSS codebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Get pandas and postgres to work together\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pd_sql\n",
    "\n",
    "import re\n",
    "import PyPDF2\n",
    "import pickle\n",
    "\n",
    "from progress_bar import log_progress\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load one of the CSVs and take a look at the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brfss_2014 = pd.read_csv(\"../data/brfss/brfss2014.csv\", encoding = \"cp1252\", nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x.state</th>\n",
       "      <th>fmonth</th>\n",
       "      <th>idate</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>iyear</th>\n",
       "      <th>dispcode</th>\n",
       "      <th>seqno</th>\n",
       "      <th>x.psu</th>\n",
       "      <th>...</th>\n",
       "      <th>x.fobtfs</th>\n",
       "      <th>x.crcrec</th>\n",
       "      <th>x.aidtst3</th>\n",
       "      <th>x.impeduc</th>\n",
       "      <th>x.impmrtl</th>\n",
       "      <th>x.imphome</th>\n",
       "      <th>rcsbrac1</th>\n",
       "      <th>rcsrace1</th>\n",
       "      <th>rchisla1</th>\n",
       "      <th>rcsbirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1172014</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>2014000001</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>2014000002</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1092014</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>2014000003</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1072014</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>2014000004</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1162014</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2014</td>\n",
       "      <td>1100</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>2014000005</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  x.state  fmonth    idate  imonth  iday  iyear  dispcode  \\\n",
       "0           1        1       1  1172014       1    17   2014      1100   \n",
       "1           2        1       1  1072014       1     7   2014      1100   \n",
       "2           3        1       1  1092014       1     9   2014      1100   \n",
       "3           4        1       1  1072014       1     7   2014      1100   \n",
       "4           5        1       1  1162014       1    16   2014      1100   \n",
       "\n",
       "        seqno       x.psu    ...     x.fobtfs  x.crcrec  x.aidtst3  x.impeduc  \\\n",
       "0  2014000001  2014000001    ...          2.0       1.0        2.0          5   \n",
       "1  2014000002  2014000002    ...          2.0       2.0        2.0          4   \n",
       "2  2014000003  2014000003    ...          2.0       2.0        2.0          6   \n",
       "3  2014000004  2014000004    ...          2.0       1.0        2.0          6   \n",
       "4  2014000005  2014000005    ...          2.0       1.0        2.0          5   \n",
       "\n",
       "   x.impmrtl  x.imphome  rcsbrac1  rcsrace1  rchisla1  rcsbirth  \n",
       "0          1          1       NaN       NaN       NaN       NaN  \n",
       "1          1          1       NaN       NaN       NaN       NaN  \n",
       "2          1          1       NaN       NaN       NaN       NaN  \n",
       "3          3          1       NaN       NaN       NaN       NaN  \n",
       "4          1          1       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_2014.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting relevant predictors from BRFSS 1999-2016\n",
    "\n",
    "BRFSS has a lot different variables, and unfortunately the name of the variables changes over the years. We need to extract the names of the variables and the description of each variable from the codebooks for each year. This is going to involve reading in each of the codebook pdf files and extracting the variable names and the description of the question that was asked for each variable. ONce we have a dictionary for the variable names and the questions, we can figure out which variables we want to get from each BRFSS CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_string(pdf_path):\n",
    "    \n",
    "    pdfFileObj = open(pdf_path, 'rb')\n",
    "    \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "    num_pages =  pdfReader.numPages\n",
    "    \n",
    "    pdf_string = \"\"\n",
    "    \n",
    "    for n in range(num_pages):\n",
    "        pageObj = pdfReader.getPage(n)\n",
    "        page_string = pageObj.extractText()\n",
    "        clean_page_string = re.sub(\"\\s+\", \" \", page_string)\n",
    "        clean_page_string = clean_page_string.strip()\n",
    "        pdf_string += clean_page_string\n",
    "        \n",
    "    # closing the pdf file object\n",
    "    pdfFileObj.close()\n",
    "    return pdf_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_var(words):\n",
    "    for word in words:\n",
    "        if word == 'BRFSS' or word == 'SAS' or len(word) <3:\n",
    "            pass\n",
    "        elif word[0] == '_':\n",
    "            return word\n",
    "        else:\n",
    "            ratio = sum([letter.isupper() for letter in list(word)])/len(list(word))\n",
    "            if ratio > 0.6:\n",
    "                return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variable_name_and_description(section):\n",
    "    words = section.split(\" \")\n",
    "    var_name = find_var(words)\n",
    "    \n",
    "    if 'Description:' in section:\n",
    "        subsections = section.split(\"Description:\")\n",
    "    elif 'Question:' in section:\n",
    "        subsections = section.split(\"Question:\")\n",
    "    else:\n",
    "        description = None\n",
    "        return var_name, description\n",
    "        \n",
    "    description = subsections[1]\n",
    "\n",
    "    value_limit = description.find(\"Value\")\n",
    "    weighted_limit = description.find(\"Weighted\")\n",
    "\n",
    "    if value_limit == -1:\n",
    "        limit = weighted_limit\n",
    "    elif weighted_limit == -1:\n",
    "        limit = value_limit\n",
    "    else:\n",
    "        limit = min(description.find(\"Value\"), description.find(\"Weighted\"))\n",
    "\n",
    "    description = description[0:limit]\n",
    "    description = description.strip()\n",
    "\n",
    "    if description == '':\n",
    "        description = None\n",
    "    \n",
    "    return var_name, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(1999, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd265ed07536452b80f0aeab4d1d9f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=19)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "codebook_dfs_dict = {}\n",
    "\n",
    "for year in log_progress(years):\n",
    "    pdf_string = extract_pdf_string(f\"../data/brfss/codebooks/{year}_codebook.pdf\")\n",
    "    pdf_sections = pdf_string.split(\"SAS Variable\")\n",
    "\n",
    "    var_desc_array = []\n",
    "    for section in pdf_sections:\n",
    "        row = extract_variable_name_and_description(section)\n",
    "        var_desc_array.append(row)\n",
    "\n",
    "    var_desc_df = pd.DataFrame(var_desc_array, columns=['var_name', 'description'])\n",
    "    \n",
    "    # We'll drop the rows where the variable is none, and then also get rid of duplicate rows where the var_names\n",
    "    # are the same.\n",
    "    var_desc_df = var_desc_df.dropna(subset=['var_name']).drop_duplicates(subset=['var_name'])\n",
    "\n",
    "    codebook_dfs_dict[year] = var_desc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickles/codebook_dfs_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(codebook_dfs_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dictionary of codebook dataframes for each year; the codebook dataframe has a column 'var_name' and a column 'description', and each row is a different variable. Now, let's try joining these dataframes together and seeing how it goes. The codebooks have different variable names for the same information between different years, which unfortunately means that in order to see how these names have evolved we have to use an outer join to get master dataframe of all of the variable names and their descriptions over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = codebook_dfs_dict[1999]\n",
    "master_df.rename(columns={'description':1999}, inplace=True)\n",
    "for year, df in codebook_dfs_dict.items():\n",
    "    if year == 1999:\n",
    "        pass\n",
    "    else:\n",
    "        master_df = pd.merge(master_df, df, how='outer', on='var_name')\n",
    "        master_df.rename(columns={'description':year}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickles/master_codebook_all_years.pkl\", \"wb\") as f:\n",
    "    pickle.dump(master_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572, 20)"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>_LLCPWT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "      <td>Final weight assigned to each respondent: Land...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_name 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010  \\\n",
       "1189  _LLCPWT  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                   2011  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2012  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2013  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2014  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2015  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2016  \\\n",
       "1189  Final weight assigned to each respondent: Land...   \n",
       "\n",
       "                                                   2017  \n",
       "1189  Final weight assigned to each respondent: Land...  "
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df.var_name=='_LLCPWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>_FINALWT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Final weight assigned to each respondent.</td>\n",
       "      <td>Final weight assigned to each respondent</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>Final weight assigned to each respondent (Post...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_name  1999  2000                                       2001  \\\n",
       "243  _FINALWT  None  None  Final weight assigned to each respondent.   \n",
       "\n",
       "                                         2002  \\\n",
       "243  Final weight assigned to each respondent   \n",
       "\n",
       "                                                  2003  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2004  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2005  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2006  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2007  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2008  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2009  \\\n",
       "243  Final weight assigned to each respondent (Post...   \n",
       "\n",
       "                                                  2010 2011 2012 2013 2014  \\\n",
       "243  Final weight assigned to each respondent (Post...  NaN  NaN  NaN  NaN   \n",
       "\n",
       "    2015 2016 2017  \n",
       "243  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df.var_name=='_FINALWT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do a merge with an inner join, which would not capture every variable name that was ever used over all the codebooks (which an outer join does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df = codebook_dfs_dict[1999]\n",
    "intersection_df.rename(columns={'description':1999}, inplace=True)\n",
    "for year, df in codebook_dfs_dict.items():\n",
    "    if year == 1999:\n",
    "        pass\n",
    "    else:\n",
    "        intersection_df = pd.merge(master_df, df, on='var_name')\n",
    "        intersection_df.rename(columns={'description':year}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>...</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_STATE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>...</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "      <td>State FIPS Code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_PSU</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Annual Sequence Number</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "      <td>Primary Sampling Unit (Equal to Annual Sequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IDATE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>...</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "      <td>Interview Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMONTH</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Month of interview</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>...</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "      <td>Interview Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDAY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Calendar date of interview</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>...</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Inte rview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "      <td>Interview Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  var_name  1999  2000                        2001                    2002  \\\n",
       "0   _STATE  None  None             State FIPS Code         State FIPS Code   \n",
       "1     _PSU  None  None                        None  Annual Sequence Number   \n",
       "2    IDATE  None  None                        None                    None   \n",
       "3   IMONTH  None  None          Month of interview         Interview Month   \n",
       "4     IDAY  None  None  Calendar date of interview           Interview Day   \n",
       "\n",
       "                                                2003  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2004  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2005  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2006  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2007  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                                2009  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2010  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                     Inte rview Day   \n",
       "\n",
       "                                                2011  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2012  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2013  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2014  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2015  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2016  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2017  \\\n",
       "0                                    State FIPS Code   \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...   \n",
       "2                                     Interview Date   \n",
       "3                                    Interview Month   \n",
       "4                                      Interview Day   \n",
       "\n",
       "                                                2017  \n",
       "0                                    State FIPS Code  \n",
       "1  Primary Sampling Unit (Equal to Annual Sequenc...  \n",
       "2                                     Interview Date  \n",
       "3                                    Interview Month  \n",
       "4                                      Interview Day  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersection_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep only the variables where 5 or fewer codebooks did not have that variable; that is, most of the codebooks contain that variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_vars = intersection_df[intersection_df.isna().sum(axis=1) <= 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to translate the master dataframe of all the variable names and their descriptions (with each year as a different column) into a dictionary. What we're interested in is the variable name as a key, and the most 'common' description as the value. The description/question wording changes between years, so we'll pick the description/question that has been used most repeatedly over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_consensus_var_desc_dict(df):\n",
    "    raw_dict = dict(pd.DataFrame.transpose(df.set_index('var_name')))\n",
    "    clean_dict = {}\n",
    "    for key, value in raw_dict.items():\n",
    "        if value.mode().empty:\n",
    "            clean_dict[key] = None\n",
    "        else:\n",
    "            clean_dict[key] = value.mode()[0]\n",
    "    return clean_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It actually makes the most sense to make a consensus variable/description dictionary from the dataframe generated by merging with outer join, because then we can look through the key/value pairs and figure out which variables are synonyms with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_var_desc_dict = make_consensus_var_desc_dict(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickles/consensus_var_desc_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(consensus_var_desc_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIABETES\n",
      "5.1. [People may] provide regular care or assistance to [someone] who is elderly or has a long -term illness or di sability. During the past month, did you provide any such care or assistance to a family member or friend who is 60+ years of age? Column: 86\n",
      "DIABEYE\n",
      "Has a doctor ever told you that diabetes has affected your eyes or that you had retinopathy?\n",
      "DIABEDU\n",
      "Have you ever taken a course or class in how to manage your diabetes yourself?\n",
      "DIABETE2\n",
      "Have you ever been told by a doctor that you have diabetes (If \"Yes\" and respondent is female, ask \"Was this only when you were pregnant?\". If Respondent says pre -diabetes or borderline diabetes, use response code 4.)\n",
      "DIABETE3\n",
      "(Ever told) you have diabetes (If \"Yes\" and respondent is female, ask \"Was this only when you were pregnant?\". If Respondent says pre -diabetes or borderline diabetes, use response code 4.)\n"
     ]
    }
   ],
   "source": [
    "for key, value in d.items():\n",
    "    if 'DIABE' in key:\n",
    "        print(key)\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_name</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DIABETES</td>\n",
       "      <td>6.1. How long has it been since you last visit...</td>\n",
       "      <td>5.1. [People may] provide regular care or assi...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>DIABETE2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>Have you ever been told by a doctor that you h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>DIABETE3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(Ever told) you have diabetes (If \"Yes\" and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If \"Yes\" and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If \"Yes\" and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If \"Yes\" and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If \"Yes\" and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If ´Yes´ and re...</td>\n",
       "      <td>(Ever told) you have diabetes (If ´Yes´ and re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_name                                               1999  \\\n",
       "40    DIABETES  6.1. How long has it been since you last visit...   \n",
       "614   DIABETE2                                                NaN   \n",
       "1088  DIABETE3                                                NaN   \n",
       "\n",
       "                                                   2000  \\\n",
       "40    5.1. [People may] provide regular care or assi...   \n",
       "614                                                 NaN   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2001  \\\n",
       "40    Have you ever been told by a doctor that you h...   \n",
       "614                                                 NaN   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2002  \\\n",
       "40    Have you ever been told by a doctor that you h...   \n",
       "614                                                 NaN   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2003  \\\n",
       "40    Have you ever been told by a doctor that you h...   \n",
       "614                                                 NaN   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2004  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2005  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2006  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2007  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2008  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2009  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2010  \\\n",
       "40                                                  NaN   \n",
       "614   Have you ever been told by a doctor that you h...   \n",
       "1088                                                NaN   \n",
       "\n",
       "                                                   2011  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If \"Yes\" and re...   \n",
       "\n",
       "                                                   2012  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If \"Yes\" and re...   \n",
       "\n",
       "                                                   2013  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If \"Yes\" and re...   \n",
       "\n",
       "                                                   2014  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If \"Yes\" and re...   \n",
       "\n",
       "                                                   2015  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If \"Yes\" and re...   \n",
       "\n",
       "                                                   2016  \\\n",
       "40                                                  NaN   \n",
       "614                                                 NaN   \n",
       "1088  (Ever told) you have diabetes (If ´Yes´ and re...   \n",
       "\n",
       "                                                   2017  \n",
       "40                                                  NaN  \n",
       "614                                                 NaN  \n",
       "1088  (Ever told) you have diabetes (If ´Yes´ and re...  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df.var_name.str.contains(\"DIABET\") == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading brfss CSVs and extracting relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (10,238) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n"
     ]
    }
   ],
   "source": [
    "brfss_1999_df = pd.read_csv(\"../data/brfss/csv/brfss1999.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x.state</th>\n",
       "      <th>x.geostr</th>\n",
       "      <th>x.denstr</th>\n",
       "      <th>x.psu</th>\n",
       "      <th>x.record</th>\n",
       "      <th>idate</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>iyear</th>\n",
       "      <th>...</th>\n",
       "      <th>x.rfdracu</th>\n",
       "      <th>x.rfdrchr</th>\n",
       "      <th>x.rfdrdri</th>\n",
       "      <th>x.raw</th>\n",
       "      <th>x.csa</th>\n",
       "      <th>x.wt1</th>\n",
       "      <th>x.poststr</th>\n",
       "      <th>x.finalwt</th>\n",
       "      <th>exerdis1</th>\n",
       "      <th>exerdis2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10290</td>\n",
       "      <td>1</td>\n",
       "      <td>1201999</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>709.955703</td>\n",
       "      <td>1419.911405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10992</td>\n",
       "      <td>1</td>\n",
       "      <td>1131999</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>919.545794</td>\n",
       "      <td>1839.091587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20586</td>\n",
       "      <td>1</td>\n",
       "      <td>2271999</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024.247333</td>\n",
       "      <td>1024.247333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20667</td>\n",
       "      <td>1</td>\n",
       "      <td>2061999</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190.937133</td>\n",
       "      <td>2381.874267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20813</td>\n",
       "      <td>1</td>\n",
       "      <td>2111999</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1190.937133</td>\n",
       "      <td>2381.874267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  x.state  x.geostr  x.denstr  x.psu  x.record    idate  imonth  \\\n",
       "0           1        1         1         1  10290         1  1201999       1   \n",
       "1           2        1         1         1  10992         1  1131999       1   \n",
       "2           3        1         1         1  20586         1  2271999       2   \n",
       "3           4        1         1         1  20667         1  2061999       2   \n",
       "4           5        1         1         1  20813         1  2111999       2   \n",
       "\n",
       "   iday  iyear    ...    x.rfdracu  x.rfdrchr  x.rfdrdri  x.raw  x.csa  x.wt1  \\\n",
       "0    20   1999    ...            1          1          1    2.0    1.0    2.0   \n",
       "1    13   1999    ...            1          1          1    2.0    1.0    2.0   \n",
       "2    27   1999    ...            1          1          1    1.0    1.0    1.0   \n",
       "3     6   1999    ...            2          1          1    2.0    1.0    2.0   \n",
       "4    11   1999    ...            1          1          1    2.0    1.0    2.0   \n",
       "\n",
       "     x.poststr    x.finalwt  exerdis1  exerdis2  \n",
       "0   709.955703  1419.911405       NaN       NaN  \n",
       "1   919.545794  1839.091587       NaN       NaN  \n",
       "2  1024.247333  1024.247333       NaN       NaN  \n",
       "3  1190.937133  2381.874267       NaN       NaN  \n",
       "4  1190.937133  2381.874267       NaN       NaN  \n",
       "\n",
       "[5 rows x 282 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brfss_1999_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_columns = [col for col in brfss_1999_df.columns if 'diabe' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in brfss_1999_df.columns:\n",
    "    if 'diabe' in col:\n",
    "        z = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['FINALWT', 'DIABET', 'LLCPWT', 'MEDCOST', 'CHOLC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['SMOKE', 'FINALWT', 'LLCPWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['CHOLC', 'TOLDHI2', 'FINALWT', 'LLCPWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['LASTCHNG', 'ASTHMA2', 'ASTHMA3', 'FINALWT', 'LLCPWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_extract = ['STATE', 'EXERANY', 'FINALWT', 'LLCPWT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalwt\n",
      "diabet\n",
      "llcpwt\n",
      "medcost\n",
      "cholc\n"
     ]
    }
   ],
   "source": [
    "for col in columns_to_extract:\n",
    "    print(col.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cols_this_df_has(list_of_columns, df):\n",
    "    good_cols = []\n",
    "    for col in df.columns:\n",
    "        temp_col = col.replace(\"x.\", \"\")\n",
    "        for col_to_extract in list_of_columns:\n",
    "            if col_to_extract.lower() in temp_col.lower():\n",
    "                good_cols.append(col)\n",
    "    return good_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smoke100', 'smokeday', 'smokenum', 'x.smoker2']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_cols_this_df_has(columns_to_extract, brfss_1999_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.3. Have you ever been told by a doctor or other health professional that your blood cholesterol is high? Column: 99'"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['CHOLC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2bee1d8f96471e9ecbc44841e4d229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=19)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (10,238) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (13,247) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,56,218,219,221,229,231) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,63) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,54) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,58,170,173,282) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,50,105,235,255) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,55,249) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,107,108) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,383) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,53,389) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,58,307) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (12,53) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (120,122) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (121) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (131) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n",
      "DtypeWarning: Columns (171) have mixed types. Specify dtype option on import or set low_memory=False. [interactiveshell.py:2785]\n"
     ]
    }
   ],
   "source": [
    "# Okay, let's go basic. Let's decide what we want to extract from each csv. How about let's extract the variable\n",
    "# smoke100 and the weight from every csv.\n",
    "list_of_temp_dfs = []\n",
    "\n",
    "for year in log_progress(years):\n",
    "    brfss_df = pd.read_csv(f\"../data/brfss/csv/brfss{year}.csv\", encoding=\"cp1252\")#, nrows=10)\n",
    "    cols = find_cols_this_df_has(columns_to_extract, brfss_df)\n",
    "#     print(year)\n",
    "#     print(cols)\n",
    "    temp_df = brfss_df[cols].copy()\n",
    "    \n",
    "    temp_df['year'] = year\n",
    "    list_of_temp_dfs.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/pickles/any_exercise_list_of_dfs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(list_of_temp_dfs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130945\n",
      "159989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    20429\n",
       "2.0     8148\n",
       "9.0      452\n",
       "7.0       15\n",
       "Name: exerany, dtype: int64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list_of_temp_dfs[0].exerany.isna().sum())\n",
    "print(len(list_of_temp_dfs[0].exerany))\n",
    "list_of_temp_dfs[0].exerany.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
